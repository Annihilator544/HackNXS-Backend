Date,Media,Title,Article,Summary,Key_words
3 hours ago,9to5Google,Google app is once again testing a bottom search bar redesign on Android,"The first time we saw a bottom search bar for the Google app was in 2021, while we enabled a modernized version in late 2023. Google is now testing a Material 3 bottom bar redesign with an integrated search field.

At least one user today has encountered this bottom bar redesign in Google Search on Android. For starters, it’s finally using Material 3 with a pill-shaped tab indicator that has rolled out on the iOS version but was seemingly abandoned on Android after a brief rollout was pulled. (That said, the Google app screenshots in the Play Store listing feature it.) That change alone plays a big role in making this first-party application a bit more consistent.

Current vs. new (@Cookie_lolll)

Above the bottom bar is the tall search field that previously only appeared at the top of the Discover feed. At the moment, that thicker variant disappears on the actual Search results page. In the redesign, it remains there for some consistency, though it does still look comically large. Overall, the combined search field and bottom bar make use of a sheet container.

One complaint would be that it takes up more space that could be used for results, but the “Google” logo no longer appears at the very top, with the Search filters immediately appearing instead.

Instead of Dynamic Color, the default blue tint is used. It does stand out against the Search results page.

Compared to the current look, this bottom search bar redesign looks more modern, with the Google app decidedly looking a bit old as of late. Hopefully, it will see a wider rollout.

L-R: 2021, 2023, 2024 (enabled)

More on Google Search:","The first time we saw a bottom search bar for the Google app was in 2021, while we enabled a modernized version in late 2023.
Google is now testing a Material 3 bottom bar redesign with an integrated search field.
At least one user today has encountered this bottom bar redesign in Google Search on Android.
(That said, the Google app screenshots in the Play Store listing feature it.)
Compared to the current look, this bottom search bar redesign looks more modern, with the Google app decidedly looking a bit old as of late.","['android', 'results', 'bar', 'look', 'google', 'app', 'testing', 'used', 'material', 'search', 'redesign', 'version']"
4 hours ago,YouTube,,,,[]
4 hours ago,Engadget,OpenAI and Google reportedly used transcriptions of YouTube videos to train their AI models,"OpenAI and Google trained their AI models on text transcribed from YouTube videos, potentially violating creators’ copyrights, according to The New York Times. The report, which describes the lengths OpenAI, Google and Meta have gone to in order to maximize the amount of data they can feed to their AIs, cites numerous people with knowledge of the companies’ practices. It comes just days after YouTube CEO Neal Mohan said in an interview with Bloomberg Originals that OpenAI’s alleged use of YouTube videos to train its new text-to-video generator, Sora, would go against the platform’s policies.

According to the NYT, OpenAI used its Whisper speech recognition tool to transcribe more than one million hours of YouTube videos, which were then used to train GPT-4. The Information previously reported that OpenAI had used YouTube videos and podcasts to train the two AI systems. OpenAI president Greg Brockman was reportedly among the people on this team. Per Google’s rules, “unauthorized scraping or downloading of YouTube content” is not allowed, Matt Bryant, a spokesperson for Google, told NYT, also saying that the company was unaware of any such use by OpenAI.

The report, however, claims there were people at Google who knew but did not take action against OpenAI because Google was using YouTube videos to train its own AI models. Google told NYT it only does so with videos from creators who have agreed to this. Engadget has reached out to Google and OpenAI for comment.

The NYT report also claims Google asked a team to tweak its privacy policy in June 2023 to more broadly cover its use of publicly available content, including Google Docs and Google Sheets, to train its AI models and products. The changes, which Google says were made for clarity's sake, were published in July. Bryant told NYT that this type of data is only used with the permission of users who opt into Google’s experimental features tests, and that the company “did not start training on additional types of data based on this language change.” The change added Bard as an example of what that data might be used for.

Correction, April 6, 2024, 3:45PM ET: This story originally stated that Google updated its privacy policy in June 2022. The policy update was actually made in 2023. We apologize for the error.","OpenAI and Google trained their AI models on text transcribed from YouTube videos, potentially violating creators’ copyrights, according to The New York Times.
According to the NYT, OpenAI used its Whisper speech recognition tool to transcribe more than one million hours of YouTube videos, which were then used to train GPT-4.
The Information previously reported that OpenAI had used YouTube videos and podcasts to train the two AI systems.
The report, however, claims there were people at Google who knew but did not take action against OpenAI because Google was using YouTube videos to train its own AI models.
Google told NYT it only does so with videos from creators who have agreed to this.","['youtube', 'nyt', 'models', 'ai', 'google', 'videos', 'data', 'reportedly', 'transcriptions', 'used', 'train', 'openai', 'told']"
5 hours ago,TechRadar,"Clash of the camera phones: I compared the iPhone 15 Pro Max, Pixel 8 Pro and Galaxy S24 Ultra – here are the pictures","If you're a discerning mobile photographer in the market for a new shooter, our best camera phone roundup should be your first port of call, but, if you're interested in how the best of the best actually perform, read on. I decided to pit the latest iPhone 15 Pro Max, Google Pixel 8 Pro and Samsung Galaxy S24 Ultra against one another in an extensive shootout to see how these top-ranking photographic champs compare.

For those not so familiar with this trio of mobile titans, here are some of the highlights. The Pixel 8 Pro – Google’s latest and greatest – delivers the company’s best AI smarts yet, thanks to its in-house Tensor G3 chip. This helps with everything from screening calls to ensuring everyone’s smiling and looking at the camera in that photo from your auntie’s 60th birthday (a feature known as Best Take).

Where photography is concerned, the 8 Pro’s hardware falls to a 50MP main sensor – boasting superior low light compared to the Pixel 7 Pro’s primary camera, a 48MP ultra-wide with a tuned macro mode and a 48MP telephoto that offers 5x optical zoom and helps facilitate the phone’s max 30x Super Res Zoom.

Apple, by comparison, hasn’t yet gone hard on branding every feature under the sun with AI, but that doesn’t make the iPhone 15 Pro Max any less of a cutting-edge powerhouse. It has one of the most capable mobile chips on the market in the company’s own A17 Pro SoC, alongside the first periscopic telephoto camera ever on an iPhone, with a unique tetraprism 5x optical zoom.

Swipe to scroll horizontally Full camera specs iPhone 15 Pro Max Pixel 8 Pro Galaxy S24 Ultra Price (at launch): $1,199 / £1,199 / AU$2,199 $999 / £999 / AU$1,699 $1,299 / £1,249 / AU$2,199 Chipset: Apple A17 Pro Google Tensor G3 Qualcomm Snapdragon 8 Gen 3 for Galaxy Main camera: 48MP, 24mm, ƒ/1.78, sensor‑shift OIS 50MP, 1.2μm pixels, ƒ/1.68, 82° FoV, 1/1.31-inch sensor size, LDAF (laser detect auto-focus), OIS 200MP, f/1.7, 24mm, 1/1.3-inch, 0.6µm pixels, multi-directional PDAF, laser AF, OIS Ultra-wide camera: 12MP, 13mm, ƒ/2.2, 120° FoV 48MP, 0.8μm pixels, ƒ/1.95, 125.5° FoV, auto-focus 12MP, f/2.2, 13mm, 120˚ FoV, 1/2.55-inch, 1.4µm pixels, dual pixel PDAF Telephoto camera: 12MP, 120mm, ƒ/2.8, 3D sensor‑shift OIS, auto-focus, 5x optical zoom via tetraprism 48MP, 0.7μm pixels, ƒ/2.8, 21.8° FoV, 5x optical zoom, Super Res Zoom up to 30x, OIS 10MP, f/2.4, 67mm, 1/3.52-inch, 1.12µm pixels, PDAF, OIS, 3x optical zoom Secondary telephoto camera: N/A N/A 50MP, f/3.4, 111mm, 1/2.52-inch, 0.7µm pixels, PDAF, OIS, 5x periscope optical zoom Front camera: 12MP, f/1.9, TrueDepth system 10.5MP, 1.22μm pixels, ƒ/2.2, 95° FoV 1/3.1-inch sensor size 12MP f/2.2, 1/3.2-inch, 1.12µm pixels, 26mm, dual pixel PDAF Key imaging technology: Sapphire crystal lens cover, Adaptive True Tone flash, Photonic Engine, Deep Fusion, Smart HDR 5, LiDAR scanner, Apple ProRAW, Dolby Vision HDR recording at up to 4K 60fps, LOG video recording, Academy Color Encoding System, Cinematic video recording Pro controls, Ultra HDR, Magic Editor, Best Take, Photo Unblur, Motion Mode, Real Tone, Night Sight, Astrophotography, Top Shot, Live HDR+, Video Boost ProVisual Engine, Reflection removal, Generative fill, Astrophotography, Pro Mode, Dual Recording, Nightography, Instant Slow-mo, Photo Assist, Super HDR, Super Steady video

Then we have the Galaxy S24 Ultra. It looks like its predecessors but boasts the best performance of any Android phone currently on the market, thanks to a custom-tuned Snapdragon 8 Gen 3 chip, a truly stunning 6.8-inch 120Hz display, a killer quad rear camera and, for a unique touch, Samsung’s iconic S Pen stylus.

Galaxy AI features can be found all over the Ultra experience, translating phone calls in real-time and letting you reframe photos with generative fill. However, like the last Ultra, camera versatility remains one of its biggest strengths.

In line with its rivals, there's now a 5x optical zoom to work with but through some clever sensor cropping, the Ultra actually affords you six lossless focal lengths, from 0.6 to 10x zoom, as well as still capture at up to 200MP, thanks to its main sensor (not to mention up to 8K 30fps video capture too).

So with the specs and features detailed, let's get on with testing those cameras in the real world.

Note: the camera being used is noted in the bottom left corner of each camera sample.

Main sensor

Starting with standard photos, shot using each phone's main snapper. These are the results from simply opening the camera app and hitting the shutter button – no settings tweaks and no lenses or modes changed first.

Tower Bridge & Millennium Bridge

Image 1 of 3 (Image credit: Future | Alex Walker-Todd)

(Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd)

We shot on a characteristically bright and cloudy day in London Town; starting with these shots of Vic against Tower Bridge (above) and later Millennium Bridge (below).

The Pixel adopted perhaps the most striking results in this well-lit scene, with strong contrast and colors. It also served up the most true-to-life colors for Vic’s skin and hair. However, the rest of the scene adopted a slight magenta tinge that looked unnatural in comparison to the other two phones.

Image 1 of 3 (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd)

The iPhone captured a nicer, brighter image – with softer contrast and a cooler overall look – and the most balanced dynamic range processing, bringing up the darkest parts of the image without making the entire scene appear flat.

The S24 Ultra – like the Pixel – miscolored the overall scene, with a slight green tint this time, but otherwise applied good color and contrast to Vic herself. The phone’s large sensor and lens resulted in a slightly wider shot with shallower depth, applying a pleasing, natural softness to the background. The end result does, however, looked a little washed out.

So while all three have specific strengths, I’d give this one to the iPhone.

Shoes

Image 1 of 3 (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd)

Next up, Vic’s blue suede shoes, captured outside with a strip of bright, cloudy sky directly above between buildings that rose high on either side.

Here, the Pixel clinches it for blending the high contrast and great detail capture – also seen on the iPhone, but with more accurate colors.

Uplighting

Image 1 of 3 (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd)

Removing natural light from the scene and relying on what was predominantly this strong uplighting, like the Tower Bridge shot, the Pixel spit out the most striking and high-contrast image, with a lot of shadow detail on the brickwork.

With Samsung’s move away from its former heavily-processed approach to photography, I think it managed the most true-to-life and visually pleasing result of the three phones here. That said, I wish it had applied the iPhone’s processing when it came to dynamic range. Apple’s phone was the only one of the three to avoid blowing out the skin on Vic's hand, even if the shot was comparatively too cool overall.

High contrast

Image 1 of 3 (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd)

One of the first sample shots taken on the day was this high-contrast scene, as I thought it would be a great way to assess how these phones handle metering and dynamic range processing. Sure enough, the results presented a lot of variation.

The Pixel’s preference for contrast is exacerbated here, with its attempts to stop down the scene in order to capture anything beyond the arch. This left the shot underexposed, overall, while the light sources still appeared blown out. It made for the most dramatic final image but the weakest of the three.

The iPhone took second place, serving up great colors and contrast, and managing to rescue some of the brightest parts of the shot in the back of the scene. Not quite as well as the S24 Ultra, though, which produced a similar result but did an amazing job more correctly exposing the entire scene. It kept all the detail beyond the arch, as well as all the lit brickwork in the foreground.

Zoom

Now let’s talk zoom. While all three of these phones have large main sensors and periscopic 5x telephoto cameras, they all handle zoom a little differently.

Image 1 of 6 (Image credit: Future | Alex Walker-Todd) 0.6x zoom (Image credit: Future | Alex Walker-Todd) 1x zoom (Image credit: Future | Alex Walker-Todd) 3x zoom (Image credit: Future | Alex Walker-Todd) 5x zoom (Image credit: Future | Alex Walker-Todd) 10x zoom (Image credit: Future | Alex Walker-Todd) 100x zoom

Samsung (above), unsurprisingly, served up the greatest versatility. Its combination of a secondary dedicated 3x telephoto sensor and sensor cropping gives you lossless shots at 0.6x, 1x, 2x, 3x, 5x and 10x magnification. In addition, that insane 100x Space Zoom feature, which might seem useless on first impressions, means you’ve got more headroom at distances between that 10x and 100x that the other phones struggle to match.

Image 1 of 5 (Image credit: Future | Alex Walker-Todd) 0.5x zoom (Image credit: Future | Alex Walker-Todd) 1x zoom (Image credit: Future | Alex Walker-Todd) 2x zoom (Image credit: Future | Alex Walker-Todd) 5x zoom (Image credit: Future | Alex Walker-Todd) 25x zoom

As for consistency and overall quality, I think the iPhone (above) deserves a pat on the back, as it doesn’t overextend like the Samsung. Even at its maximum zoom range, 25x lossy shots still held an impressive amount of detail and information that's wholly usable.

Image 1 of 5 (Image credit: Future | Alex Walker-Todd) 0.5x zoom (Image credit: Future | Alex Walker-Todd) 1x zoom (Image credit: Future | Alex Walker-Todd) 2x zoom (Image credit: Future | Alex Walker-Todd) 5x zoom (Image credit: Future | Alex Walker-Todd) 30x zoom

The Pixel (above) didn't disappoint in this test but it just received a participation award here. It served up consistent and usable shots but they don’t turn heads like the other two.

Image 1 of 3 (Image credit: Future | Alex Walker-Todd) 24mm on the 15 Pro Max (Image credit: Future | Alex Walker-Todd) 28mm on the 15 Pro Max (Image credit: Future | Alex Walker-Todd) 35mm on the 15 Pro Max

Also, don’t fall for Apple’s 24mm, 28mm, 35mm lens marketing (above), it’s just cropping on the main sensor, which I’d advise you do in post instead, for greater control.

Low light

While all three phones can deliver in conventional low light shooting scenarios, like nights out and at dusk, I wanted to see what work the image processing and sensors have to do when the lights get low. As such, we shot in a windowless room with the door almost completely shut – to the point where I could only just make out the plants on the wall with the naked eye.

First, here's the scene with the lights on, to serve as a baseline for what each phone's low light and Night modes are striving for.

The scene before the lights were turned off (Image credit: Future | Alex Walker-Todd)

Night mode off

Image 1 of 3 (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd)

Low light capture without Night mode proved (unsurprisingly) challenging for all three phones. The iPhone cranked the ISO up to retain the most sharpness and detail, at the expense of exhibiting the most sensor noise.

With Google’s well-established prowess with Night Sight, the Pixel didn’t even try here; creating a sort of pink sludgy shot with such underwhelming detail and color information that it looked like it was shot using infrared.

The S24 Ultra made the best of a bad situation, offering sharper detail than the Pixel and less noise than the iPhone in exchange for its characteristic green tint across the scene.

Night mode on

Image 1 of 3 (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd)

Flipping to Night mode, the Samsung showed the least improvement; struggling to recover much color detail or improve exposure much over the standard low light sample.

The iPhone boasted the fastest Night mode capture time and produced a usable shot with good detail but poor dynamic range. Not to mention it added a yellow hue to the scene.

The Pixel, meanwhile, moved from the back to the front of the pack, by being able to render a shot that looked like it was taken in a lit room. It’s still dim, sure, but there’s clear definition in the subject, tangible detail in the shadows and you can tell that the leaves on the plants are, in fact, green.

Portrait mode

Portrait mode using the main cameras on each phone yielded some interesting results. Both Android phones struggled to segment Vic from the background cleanly, while the iPhone over-softened her slightly in both scenarios.

Image 1 of 3 (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd)

In all three phones' images, the level of bokeh looked too extreme as standard, with the iPhone offering the most effective adjustment over this attribute after capture. The Pixel won the award for subject detail, while the S24 Ultra managed the most accurate colors.

Image 1 of 3 (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd)

While all three phones crop in by default, the Pixel locks you into a 1.5x zoom as standard. You can punch much further out with the Galaxy and iPhone.

Selfies

All these shots are taken using each phone's front camera, with a mix of Portrait mode enabled or disabled, depending on the sample.

Image 1 of 12 (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd)

The Pixel’s tendency to increase contrast and under-expose in bright conditions carried across to its front 10.5MP camera. The iPhone and Galaxy’s 12MP selfie snappers were brighter and retained more face detail in direct comparison.

The S24 captured the narrowest field of view and had that characteristic green tint but offered the best overall composition – covering color, contrast and detail capture. The iPhone once again won for edge detection around challenging elements like hair and offering the most natural-looking bokeh, even if shots erred on the cooler side once more.

Video

Finishing with video capture, our 4K 60fps test footage revealed that, while close, the iPhone’s stabilization and autofocus tracking ruled supreme, but that color and contrast take a nosedive compared to the still shots the phone can produce.

The S24 Ultra over-exposed and over-sharpened footage but did the best job at filtering out wind noise. The Pixel came out on top, even without leaning on its AI-enhanced Video Boost feature.

Not only did footage more closely match still photo quality and fidelity, but provided you’re happy with the degree to which it punches in, you get a warmer and more filmic image overall, with attractive depth of field from that main 50MP sensor.

It’s worth noting that if you’re looking for a new phone to slot into a content capture workflow, the iPhone arguably has the best codecs and toolset, with Samsung’s flagship offering has the highest degree of control at capture.

Conclusion

So with these titans thoroughly tested, we can't say there's a clear-cut champ but rather the winner depends on which photographic qualities matter most to you. Are you a fan of the Pixel’s Night mode photography, or more a lover of the iPhone’s bokeh? Perhaps the sheer breadth of features and versatility offered by the S24 Ultra gets your vote.

Whichever device made the most convincing argument, just know that you're getting one of the industry's best right now.

You may also like

The iPhone 15 Pro Max used in this review was supplied by Vodafone UK. Click here for Vodafone's latest iPhone deals.","ShoesImage 1 of 3 (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd)Next up, Vic’s blue suede shoes, captured outside with a strip of bright, cloudy sky directly above between buildings that rose high on either side.
Image 1 of 6 (Image credit: Future | Alex Walker-Todd) 0.6x zoom (Image credit: Future | Alex Walker-Todd) 1x zoom (Image credit: Future | Alex Walker-Todd) 3x zoom (Image credit: Future | Alex Walker-Todd) 5x zoom (Image credit: Future | Alex Walker-Todd) 10x zoom (Image credit: Future | Alex Walker-Todd) 100x zoomSamsung (above), unsurprisingly, served up the greatest versatility.
Image 1 of 5 (Image credit: Future | Alex Walker-Todd) 0.5x zoom (Image credit: Future | Alex Walker-Todd) 1x zoom (Image credit: Future | Alex Walker-Todd) 2x zoom (Image credit: Future | Alex Walker-Todd) 5x zoom (Image credit: Future | Alex Walker-Todd) 30x zoomThe Pixel (above) didn't disappoint in this test but it just received a participation award here.
The scene before the lights were turned off (Image credit: Future | Alex Walker-Todd)Night mode offImage 1 of 3 (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd)Low light capture without Night mode proved (unsurprisingly) challenging for all three phones.
Image 1 of 12 (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd) (Image credit: Future | Alex Walker-Todd)The Pixel’s tendency to increase contrast and under-expose in bright conditions carried across to its front 10.5MP camera.","['future', 'max', 'credit', 'alex', 'pictures', 'phones', 'iphone', 'compared', 'image', 'zoom', 'pixel', 'camera', 's24', 'ultra', 'galaxy', 'pro', 'walkertodd']"
5 hours ago,The Verge,Google’s Pixel Buds Pro are $60 off in all colors — including the newest shades,"Happy Saturday, folks! Ever since they arrived on the scene in mid-2022, we’ve considered Google’s noise-canceling Pixel Buds Pro to be the wireless earbuds for Pixel phone owners — partly because of their great feature set and partly because they addressed the connectivity issues that plagued earlier models. The best part, however, is they’re often on sale for far less than the MSRP. Right now, for instance, you can pick them up at Amazon, Walmart, and Best Buy for around $139 ($60 off), which matches their second-best price to date.

In terms of features, Google’s latest Pixel Buds are designed to compete with the best from Apple, Sony, and others. Their noise cancellation can’t quite match the latest AirPods Pro or what Bose has achieved with the QuietComfort Ultra Earbuds, though it’s still very good, particularly if all you're trying to do is drown out the sound of a coffee shop or office. They also include multipoint support and, thanks to a welcome firmware update that dropped in the fall, new conversation tech that will automatically engage their transparency mode and pause whatever audio you’re listening to when you begin to speak. Couple that with a long-lasting battery capacity and a handful of Pixel-exclusive features — including native controls and head tracking spatial audio — and it’s easy to understand why they remain our No. 1 pick if you’re already tapped into the Google ecosystem.

Truth be told, I’ve never been a huge fan of most key lights, many of which opt for a circular or square-ish design that’s a bit of an eyesore when placed above your monitor. Logitech’s Litra Beam takes a more subtle approach to illumination, however, relying on a low-profile form factor that should sit neatly atop your monitor or the included stand. What’s more, it’s currently available from Amazon, Best Buy, and Logitech for $89.99 ($10 off), nearly matching its all-time low.

As you might imagine, Logitech’s full-spectrum LED key light is purpose-built for streaming, podcasting, or taking video calls from home. It’s sleeker than similar offerings like Razer’s Key Light Chroma and Elgato’s new Key Light MK.2, which allows it to align squarely with the top of your monitor or easily be adjusted to act as a traditional desk lamp when you’re not streaming. It sports adjustable brightness and color temperature, too, the latter of which you can tune between a relatively warm 2700K and a super cool 6500K using either the onboard hardware controls or Logitech’s G Hub desktop app. As for compatibility, it works with macOS and Windows via USB and Bluetooth, though you will need to plug the USB cable in for power regardless of which connection method you choose.

Verge Deals on X / Join more than 50,000 followers and keep up with the best daily tech deals with @vergedeals Follow us!

More ways to save this weekend","The best part, however, is they’re often on sale for far less than the MSRP.
In terms of features, Google’s latest Pixel Buds are designed to compete with the best from Apple, Sony, and others.
What’s more, it’s currently available from Amazon, Best Buy, and Logitech for $89.99 ($10 off), nearly matching its all-time low.
As you might imagine, Logitech’s full-spectrum LED key light is purpose-built for streaming, podcasting, or taking video calls from home.
Verge Deals on X / Join more than 50,000 followers and keep up with the best daily tech deals with @vergedeals Follow us!","['usb', 'key', 'best', 'googles', 'colors', 'newest', 'pixel', 'streaming', '60', 'buds', 'including', 'shades', 'tech', 'pro', 'logitechs', 'light', 'youre', 'monitor']"
8 hours ago,Futurism,Google Accidentally Admits Something Very Funny About AI,"Oops!

Big Shot, Big Foot

Google is reportedly considering charging users a subscription to access its experimental AI-integrated search feature — a proposed measure that would mark the first time the search giant has ever charged users for access to a core feature.

That Google's even weighing such a shift — first reported by The Financial Times — is striking. Google Search rakes in an incredible amount of money without subscription fees, and Google has an arguably monopolistic chokehold on the search marketplace.

On the one hand, charging users to access AI search could point to the sheer amount of money and resources it takes to power AI systems in the first place. But as The Guardian's Alex Hern points out, the search giant's potential willingness to lock its AI search behind pay-to-play doors seemingly illustrates a unique, self-made problem for Google: that the AI it's so eager to integrate into its search platform stands to upend the ad model that makes the company the vast majority of its revenue.

""Google search prints money. Generative AI burns money,"" writes Hern. ""What happens when an unstoppable force hits an immovable object?""

Disrupt Yourself

Google's current ad model is simple. Companies pay Google, and the search giant places advertisements across websites. Users see the ads both in the company's search results and when they click on one of their endless blue links. Ideally, the brand that's coughing up the ad dollars makes some sales. And Google wins no matter what.

But as Hern explains, in its current state, Google's AI-integrated search feature — currently dubbed ""search generative experience,"" or SGE — pretty much annihilates this system.

SGE is designed to paraphrase web results; rather than comprise a clean list of links to outside websites, the AI tool effectively swallows web results and spits them back out at the user. And though SGE does offer some links out to its sources, the AI-infused product fundamentally disincentivizes users from clicking through them. And if users don't surf those ad-laden links, where does that leave Google's baseline revenue model?

Worse, an AI result is just way more expensive to serve than a traditional page, both in infrastructure and energy costs.

Google isn't the only search company wrestling with the question of how to make an ad model work for AI-powered search. Perplexity, an up-and-coming AI ""answer engine,"" is toying with the idea of allowing brands to ""sponsor"" certain follow-up search queries, according to a recent report from Adweek.

Google's subscription idea certainly feels ethically sounder than branding the concept of information. But it would still be a massive shift for the company, and this latest conundrum adds to the growing tension between Google's role as the world's premier search engine and its drive to compete in the heated AI race.

More on Google and AI: Google Considering Making Users Pay for AI Search Results","Google Search rakes in an incredible amount of money without subscription fees, and Google has an arguably monopolistic chokehold on the search marketplace.
On the one hand, charging users to access AI search could point to the sheer amount of money and resources it takes to power AI systems in the first place.
""Google search prints money.
Google's subscription idea certainly feels ethically sounder than branding the concept of information.
More on Google and AI: Google Considering Making Users Pay for AI Search Results","['results', 'ai', 'users', 'google', 'links', 'googles', 'ad', 'subscription', 'accidentally', 'funny', 'search', 'money', 'admits']"
8 hours ago,Tom's Guide,Android 15 is getting a huge upgrade that surpasses the iPhone,"Last year, it was rumored that Google would introduce a full desktop mode with the Pixel 8 line. Though the company enabled display output on the handsets last month, the experience is still fairly underwhelming.

But that might not be the case for too much longer, according to Android Authority, which has found evidence showing that Google has been improving desktop mode in the background. This could mean that Google plans to launch it with the upcoming Android 15 update.

As the piece points out, desktop mode has existed since 2019 with Android 10, but it’s severely underbaked. As it stands, it's intended for developers to test their apps in multi-display usage rather than for buyers to use their phones like a PC. It lacks many basic features you’d expect for it to be genuinely useful to the average user.

Using the Android 14 QPR Beta 2.1 build, the site’s Mishaal Rahman was able to enable the desktop mode experience in its current state, and it seems to have come a long way in the last few years.

As the video above demonstrates, Android desktop mode behaves a bit more like Windows, macOS, and Linux than it used to. Windows not only now has titles and icons, but they can be dragged around and resized at will. Minimizing, maximizing, and snapping to screen edges are all also now possible.

It’s a big improvement, but it’s important not to oversell it as a full desktop solution. In its current state, it still lacks many things that desktop users will take for granted, like keyboard shortcuts and what Rahman calls “a robust desktop launcher.” On top of that, plenty of apps still don’t support drag and drop, which clips the mode’s wings considerably.

These things can — and likely will — be fixed, but it will take time. This might be something we see debuting at Google I/O in May, alongside the Pixel 9 this fall, or even later.

Sign up to get the BEST of Tom’s Guide direct to your inbox. Upgrade your life with a daily dose of the biggest tech news, lifestyle hacks and our curated analysis. Be the first to know about cutting-edge gadgets and the hottest deals. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors

In the meantime, those who want a phone that offers a good experience in both mobile and desktop use should consider Samsung phones with DeX support or Motorola handsets with Ready For. Both offer an experience that’s stronger than the stock Android one, but hopefully, that won’t be the case for too much longer.","Last year, it was rumored that Google would introduce a full desktop mode with the Pixel 8 line.
But that might not be the case for too much longer, according to Android Authority, which has found evidence showing that Google has been improving desktop mode in the background.
This could mean that Google plans to launch it with the upcoming Android 15 update.
As the piece points out, desktop mode has existed since 2019 with Android 10, but it’s severely underbaked.
As the video above demonstrates, Android desktop mode behaves a bit more like Windows, macOS, and Linux than it used to.","['surpasses', 'android', 'experience', 'support', 'iphone', 'google', 'things', 'windows', 'desktop', 'state', 'rahman', 'mode', 'huge', 'getting', '15', 'upgrade']"
8 hours ago,Bar and Bench,Google Play not itself a Payment Aggregator but RBI will take final call: Calcutta High Court,"Justice Sabyasachi Bhattacharyya gave the ex facie (on the face of it) finding while rejecting Bengali over-the-top (OTT) platform Hoichoi's plea for protection against de-listing from Google Play Store over its non-acceptance of Google Play Billing System (GPBS)

However, the Court clarified that the Reserve Bank of India (RBI) shall take the final decision on Hoichoi's complaint which alleged that Google Group companies by employing the GPBS for facilitation of payment transactions on Play Store, were violating the Payment and Settlement Systems Act, 2007

""The issues raised are at best arguable and are to be decided by the RBI, which is the designated regulatory and adjudicatory authority under the PSS Act which has its own ecosystem for dealing with contraventions of the said Act,"" the Court said in the order.","Justice Sabyasachi Bhattacharyya gave the ex facie (on the face of it) finding while rejecting Bengali over-the-top (OTT) platform Hoichoi's plea for protection against de-listing from Google Play Store over its non-acceptance of Google Play Billing System (GPBS)However, the Court clarified that the Reserve Bank of India (RBI) shall take the final decision on Hoichoi's complaint which alleged that Google Group companies by employing the GPBS for facilitation of payment transactions on Play Store, were violating the Payment and Settlement Systems Act, 2007""The issues raised are at best arguable and are to be decided by the RBI, which is the designated regulatory and adjudicatory authority under the PSS Act which has its own ecosystem for dealing with contraventions of the said Act,"" the Court said in the order.","['play', 'aggregator', 'google', 'high', 'court', 'act', 'store', 'hoichois', 'final', 'calcutta', 'violating', 'transactions', 'rbi', 'payment']"
9 hours ago,The Nation Newspaper,,,,[]
9 hours ago,Business Insider,,,,[]
